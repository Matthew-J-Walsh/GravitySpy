#!/usr/bin/env python

# Goal of this function is to complete the following work flow
# 1) Get some Omicron triggers (source: ~detchar/triggers XML)
# 2) Get ANALYSIS_READY segments from the segdb
# 3) Filter 1 to take out anything that is not in 2.
# 4) Filter 3 to only include triggers with SNR>6 and 10<=freq<2048.  
# 5) Write some new Omicron XML files (or even text files or HDF5 files) that contain the triggers that were in ANALYSIS_READY and have SNR>6. 
# 6) Create Omega Scans of the remaining omicron triggers

# -------------------------------------------------------------------------
#      Setup.
# -------------------------------------------------------------------------

# ---- Import standard modules to the python path.
from gwpy.table.lsctables import SnglBurstTable
from gwpy.segments import DataQualityFlag
import os,time, optparse, csv,sys,pickle,shlex,subprocess

###############################################################################
##########################                             ########################
##########################   Func: parse_commandline   ########################
##########################                             ########################
###############################################################################
# Definite Command line arguments here

def parse_commandline():
    """
    Parse the options given on the command-line.
    """
    parser = optparse.OptionParser()
    parser.add_option("--boxtime", help="Different time ranges (1 would represent +-0.5 around central time) for displaying the glitch) For Example: '[0.5 1 4 16]' would give you four differnt images with those different times boxes [Default:[0.5,1,2,4]",
                        default=[0.5,1,2,4])
    parser.add_option("--channelname", help="channel name [Default:GDS-CALIB_STRAIN]",
                        default="GDS-CALIB_STRAIN")
    parser.add_option("--colorMap", help="What color would you like the omegascans to be? [Default: jet] [Options: bone, copper,hot]", default="jet")
    parser.add_option("--detector", help="detector name [L1 or H1]. [No Default must supply]")
    parser.add_option("--durHigh", help="The max duration of a glitch you want to make images for [Optional Input]",type=float)
    parser.add_option("--durLow", help="lower duration of a glitch you want to make images for[Optional Input]",type=float)
    parser.add_option("--gpsStart", help="gps Start Time of Query for meta data and omega scans. [No Default must supply]")
    parser.add_option("--gpsEnd", help="gps End Time [No Default must supply]")
    parser.add_option("--freqHigh", help="upper frequency bound cut off for the glitches. [Default: 2048]",type=int,default=2048)
    parser.add_option("--freqLow", help="lower frequency bound cut off for the glitches. [Default: 10]",type=int,default=10)
    parser.add_option("--ID", help="Filename of UniqueIDs you would like to make images for (generally done if desiring to see same image but in a different way.",default='somethingthatcantbefile.txt')
    parser.add_option("--imagepath", help="path to directory for images NO matter what path you select {detectorname}_{gpsStart}_{gpsEnd} will be added as a subdirectory [Default ~/public_html/GravitySpy/]",
                        default='~/public_html/GravitySpy/')
    parser.add_option("--nds2name", help="ip address or URL of the nds2\
                        server to use [Default: nds.ligo.caltech.edu]",
                        default="nds.ligo.caltech.edu")
    parser.add_option("--normalizedSNR", help="SNR Normalization value. [Default: 25.5]",type=float,default=25.5)
    parser.add_option("--masterID", help="path to master ID file that contains all the original IDs and GPStimes [Default: None but must supply if supplying a ID file from which to make images.]")
    parser.add_option("--maxSNR", help="This flag gives you the option to supply a upper limit to the SNR of the glitches [Optional Input]",type=float)
    parser.add_option("--outpath", help="path to output directory [Default: ./png] (This is where the images are created but you will not have to go in this folder as the iamges are transferred to your public_html imagepath folder)",
                        default=os.getcwd() + '/png')
    parser.add_option("--runlocal", help="run locally (running as a condor job has not been set up yet)",type=int,default=1)
    parser.add_option("--sampfrequency", help="sample frequency for omegascan iamges [Default: 4096]", type=int,default=4096)
    parser.add_option("--SNR", help="Lower bound SNR Threshold for omicron triggers, by default there is no upperbound SNR unless supplied throught the --maxSNR flag. [Default: 6]",type=float,default=6)
    parser.add_option("--username", help="albert.einstein LIGO username. (only needed when running a condor sub) [Default: scott.coughlin]",default="scott.coughlin")
    parser.add_option("--verbose", action="store_true", default=False,
                      help="Run verbosely. (Default: False)")

    opts, args = parser.parse_args()

    return opts

###############################################################################
##########################                              #######################
##########################   Func: threshold            #######################
##########################                              #######################
###############################################################################
# Define threshold function that will filter omicron triggers based on SNR and frequency threshold the user sets (or the defaults.)

def threshold(row):
    passthresh = True
    if not opts.durHigh is None:
	passthresh = ((row.duration <= opts.durHigh) and passthresh)
    if not opts.durLow is None:
        passthresh = ((row.duration >= opts.durLow) and passthresh)
    if not opts.freqHigh is None:
        passthresh = ((row.peak_frequency <= opts.freqHigh) and passthresh)
    if not opts.freqLow is None:
        passthresh = ((row.peak_frequency >= opts.freqLow) and passthresh)
    if not opts.maxSNR is None:
        passthresh = ((row.snr <= opts.maxSNR) and passthresh)
    if not opts.SNR is None:
        passthresh = ((row.snr >= opts.SNR) and passthresh)
    return passthresh

###############################################################################
##########################                          ###########################
##########################   Func: make_images      ###########################
##########################                          ###########################
###############################################################################

# This takes in information from omicron triggers and generates images and IDs (this function is for running locally.)
def make_images(centraltime,iT=0):

    # Make temporary directory to create the images in
    system_call = 'mktemp -d {0}/{1}/AAA.XXXXXXXXXX'.format(opts.outpath,detGPSstr)
    os.system(system_call)
    
    tempname = os.listdir("{0}/{1}/".format(opts.outpath,detGPSstr))
    tempdir = ('{0}/{1}/'.format(opts.outpath,detGPSstr) + tempname[0])
    # Check if IDs already provided if not they will be generated by the random folder name
    if 'IDinput' in globals():
	uniqueid = IDinput[iT]
    else:
    	uniqueid = tempname[0].split('.')[1]
    	print('unique id is {0}'.format(uniqueid))

    system_call = 'rm -rf {0}'.format(tempdir)
    os.system(system_call)

    # Use random folder name as I.D. Tag but first check if this gps time 
    # already has a I.D. tag and use that if it does.
    idfile =  open('./ID/ID_' + detGPSstr + '.txt', "a+")
    idfile.write('{0} {1} {2}\n'.format(detchannelname,centraltime,uniqueid))
    idfile.close()
    # Open file for writing metadata for images
    metadata =  open(imagepathname + '/imagemetadata.txt', "a+")

    system_call = "wscan {0} {1} {2} {3}_HOFT_C00 ./cache/{4}.cache {5} 2".format(centraltime,uniqueid,detchannelname,opts.detector,detGPSstr,imagepathname)

    if opts.verbose == True:
	print(system_call)

    os.system(system_call)


    # Start row for image metdata that assists in the uploading of the images to the project builder.
    metadata.write('{0} 20151016 '.format(uniqueid))

    # Start loop over image where we chop off the GPS time of the image.

    for iTime in xrange(0,len(opts.boxtime)):

	if iTime == (len(opts.boxtime)-1):
	    # Last entry cannot contain a space otherwise conversion from txt 
	    # to csv file would not work.
	    metadata.write('{0}_{1}.png'.format(uniqueid,opts.boxtime[iTime]))
	else:
	    # Add image string to image metadata csv file.
	    metadata.write('{0}_{1}.png '.format(uniqueid,opts.boxtime[iTime]))

    metadata.write('\n')
    metadata.close()

    return uniqueid

###############################################################################
##########################                          ###########################
##########################   Func: verbosity        ###########################
##########################                          ###########################
###############################################################################

# Function to spit out useful verbosity whether generating a submission file or running locally.

def verbosity():

    # Let the user know what detector and channel combo they have selected.
    print "You have selected detector channel combination {0}".format(detchannelname)

    # Let the user know which SNR cut they have selected.
    print "You have selected a SNR cut of {0}".format(opts.SNR)

    # Let the user know which SNR normalization max they have selected.
    print "You have selected a SNR normalization max of {0}".format(opts.normalizedSNR)

    # Let the user know which colormpa color they have  selected.
    print "You have selected a colormap color of {0}".format(opts.colorMap)

    # Where will the images be generated
    print('Images will be made:' + opts.outpath)

    # Where will the final images end up
    print('Path to directory where final images will appear:' + imagepathname)

###############################################################################
##########################                          ###########################
##########################   Func: get_triggers     ###########################
##########################                          ###########################
###############################################################################

# This function queries omicron to obtain trigger times of the glitches. It then proceeds to filter out these times based on whether the detector was in an analysis ready state or the glitch passes certain frequency and SNR cuts. 

def get_triggers():

    # Obtain segments from L1 that are analysis ready
    analysis_ready = DataQualityFlag.query('{0}:DMT-ANALYSIS_READY:1'.format(opts.detector),opts.gpsStart,opts.gpsEnd)

    # Display segments for which this flag is true
    print "Segments for which the ANALYSIS READY Flag is active: {0}".format(analysis_ready.active)

    # Fetch raw omicron triggers and apply filter which is defined in a function above.
    omicrontriggers = SnglBurstTable.fetch(detchannelname,'Omicron',\
    opts.gpsStart,opts.gpsEnd,filt=threshold)

    print "List of available metadata information for a given glitch provided by omicron: {0}".format(omicrontriggers.columnnames)

    print "Number of triggers after SNR and Freq cuts but before ANALYSIS READY flag filtering: {0}".format(len(omicrontriggers))

    # Filter the raw omicron triggers against the ANALYSIS READY flag.
    omicrontriggers = omicrontriggers.vetoed(analysis_ready.active)

    print "Final trigger length: {0}".format(len(omicrontriggers))

    return omicrontriggers

###############################################################################
##########################                            #########################
##########################   Func: write_dagfile     #########################
##########################                            #########################
###############################################################################

# Create some variable and file directories based on inputs

def setup():

    # Take the detector and the channel from the command line and combine them into one string. This is needed for some input later on.
    detchannelname = opts.detector + ':' +  opts.channelname

    # Need to strip the 1 away from detector name
    detstrip = opts.detector.split('1')[0]

    # Create a string of detector name, gpsStart and gpsEnd time that will be used repeatedly throughout code

    detGPSstr = opts.detector + '_'  + str(opts.gpsStart) + '_' + str(opts.gpsEnd)

    # Take imagepath add a directory indicating the detector and the gpsStart and gpsEnd times

    imagepathname = os.path.expanduser(opts.imagepath) + '/' + detGPSstr + '/'
    system_call = 'mkdir -p ' + imagepathname
    os.system(system_call)

    # create a path where the images will get generated

    system_call = 'mkdir -p ' + opts.outpath + '/' + detGPSstr
    os.system(system_call)

    # Create the path to the glitch metadata
    system_call = 'mkdir -p glitchmetadata'
    os.system(system_call)

    # Create cache file directory.
    system_call = 'mkdir -p cache'
    os.system(system_call)

    # Create ID file directory
    system_call = 'mkdir -p ID'
    os.system(system_call)

    # Create condor directory where all files will go if running a condor job.
    system_call = 'mkdir -p condor'
    os.system(system_call)
    
    # Create logs file for the logfiles of the condor jobs should you be not
    # Running locally.
    system_call = 'mkdir -p logs'
    os.system(system_call)

    # open a txt file where the image metadata for consumption by the Zooniverse servers will be stored.
    metadata =  open(imagepathname + '/imagemetadata.txt', "w+")
    metadata.write('ID Date Filename1 Filename2 Filename3 Filename4\n')
    metadata.close()

    # Open metadata file for GLITCH metadata information
    glitchmetadata = open('./glitchmetadata/data_' + detGPSstr + '.txt',"w+")
    # Headers indicating the metadata WE have selected as of right now.
    # SNR, Amplitude, peak_freq, cent_freq, duration, bandwidth, UniqueID
    glitchmetadata.write('# SNR, Amplitude, peak_freq, cent_freq, duration, bandwidth, UniqueID\n')
    glitchmetadata.close()

    # open Id.txt which will store the link between GPS time and Randomly Generated Unqiue ID of an image
    idfile =  open('./ID/ID_' + detGPSstr + '.txt', "w+")
    idfile.write('# Channel GPSTime UniqueID\n')
    idfile.close()

    return detchannelname, detstrip, detGPSstr, imagepathname

###############################################################################
##########################                            #########################
##########################   Func: call_data_find     #########################
##########################                            #########################
###############################################################################

# Call gw_data_find in order to create a cache file to be parsed by dmt_wplot. This is significantly faster way to get images generated then going through the NDS2 server.

def call_data_find():
    
    system_call = 'gw_data_find --observatory={0} -s {1} -e {2} --type={3}_HOFT_C00  -W > ./cache/{4}.cache'.format(detstrip,opts.gpsStart,opts.gpsEnd,opts.detector,detGPSstr)
    print('Cache file generated by the following: {0}'.format(system_call))
    os.system(system_call)

###############################################################################
##########################                            #########################
##########################   Func: write_subfile     #########################
##########################                            #########################
###############################################################################

# Write submission file for the condor job

def write_subfile():
    with open('./condor/gravityspy.sub', 'w') as subfile:
    	subfile.write('universe = vanilla\n')
        subfile.write('executable = {0}/read_omicron_triggers\n'.format(os.getcwd()))
	subfile.write('\n')
        subfile.write('arguments = "--gpsStart $(gpsStart) --gpsEnd $(gpsEnd) --detector {0} --runlocal 2"\n'.format(opts.detector))
        subfile.write('getEnv=True\n')
	subfile.write('\n')
        subfile.write('accounting_group_user = {0}\n'.format(opts.username))
        subfile.write('accounting_group = ligo.dev.o1.detchar.ch_categorization.glitchzoo\n')
	subfile.write('\n')
        subfile.write('priority = 0\n')
        subfile.write('request_memory = 1000\n')
	subfile.write('\n')
        subfile.write('error = logs/gravityspy-$(jobNumber).err\n')
        subfile.write('output = logs/gravityspy-$(jobNumber).out\n')
        subfile.write('notification = never\n')
        subfile.write('queue 1')

###############################################################################
##########################                            #########################
##########################   Func: write_dagfile     #########################
##########################                            #########################
###############################################################################

# Write dag_file file for the condor job

def write_dagfile():
    with open('gravityspy.dag','a+') as dagfile:
	dagfile.write('JOB {0} ./condor/gravityspy.sub\n'.format(opts.gpsStart))
	dagfile.write('RETRY {0} 3\n'.format(opts.gpsStart))
	dagfile.write('VARS {0} jobNumber="{0}" gpsStart="{0}" gpsEnd="{1}"'.format(opts.gpsStart,opts.gpsEnd))
	dagfile.write('\n\n')


###############################################################################
##########################                            #########################
##########################   Func: main_call          #########################
##########################                            #########################
###############################################################################

# This function loops over omicron triggers calling the make_images and writing the glitch metadata.

def main_call():
    # Check if IDs already supplied
    if 'IDinput' in globals():
        for iT in xrange(0,len(IDinput)):
                start=time.time()
                # Run the function make_images which will generate the image and
 		# utilize the IDs already supplied
                uniqueid = make_images(centraltimelist[iT],iT)

                # For this trigger we don not need metadata since
		# That metadata has already been written. 

                end =time.time()
                print('Image took {0} seconds to generate and you are {1} percentage of the way through todays images'.format(end-start,100*float(iT)/float(len(IDinput))))
    # Else just continue with standard image generation.
    else:
    	# Initialize variable to keep track of how many images you have made 
    	# so far from entire trigger set.
    	iT =0
    	for omicrontrigger in omicrontriggers:
    		start=time.time()
    		# Run the function make_images which will generate the image and create an uniqueID to assign to that image
    		uniqueid = make_images('{0}.{1}'.format(omicrontrigger.peak_time,omicrontrigger.peak_time_ns))

    		# For this trigger write all the metadata of the trigger plus the unqiueID generated during make_images 

    		with open('./glitchmetadata/data_' + detGPSstr + '.txt','a+') as f:
        	    f.write('{0} {1} {2} {3} {4} {5} {6}\n'.format(omicrontrigger.snr,omicrontrigger.amplitude,omicrontrigger.peak_frequency,omicrontrigger.central_freq,omicrontrigger.duration,omicrontrigger.bandwidth,uniqueid))
        	    f.close()

		iT=iT+1
    		end =time.time()
    		print('Image took {0} seconds to generate and you are {1} percentage of the way through todays images'.format(end-start,100*float(iT)/float(len(omicrontriggers))))

###############################################################################
##########################                            #########################
##########################   Func: obtain_IDs         #########################
##########################                            #########################
###############################################################################

# Make images from supplied unique IDs

def obtain_IDs():
    centraltimelist = []
    IDfile = open(opts.ID,'r')
    IDinput = IDfile.read().splitlines()
    for rows in xrange(0,len(IDinput)):
        commandline = 'grep "{0}" {1}'.format(IDinput[rows],opts.masterID)
        proc = subprocess.Popen(shlex.split(commandline), stdout=subprocess.PIPE)
        output = proc.stdout.read()
        output = output.split(detchannelname)[1]
        ctime   = output.split(' ')[1]
	centraltimelist.append(ctime)

    return centraltimelist,IDinput

###############################################################################
##########################                            #########################
##########################   Func: image_pp           #########################
##########################                            #########################
###############################################################################

# Convert image metadata to API readable csv file and tar up the png to ease in transfer

def image_pp():
    # We must now convert image metadata to CSV to prep for upload.

    txt_file = imagepathname  + '/imagemetadata.txt'
    csv_file = imagepathname  + '/imagemetadata.csv'
    in_txt = csv.reader(open(txt_file, "rb"), delimiter = ' ')
    out_csv = csv.writer(open(csv_file, 'wb'))
    out_csv.writerows(in_txt)
    system_call = 'tar -czvf ' + imagepathname + '/' + detGPSstr + '.tar ' + imagepathname  + '/*.png'
    os.system(system_call)

###############################################################################
##########################                     ################################
##########################      MAIN CODE      ################################
##########################                     ################################
###############################################################################

# Parse commandline arguments

opts = parse_commandline()

# Depending on if you are running locally or not. If not running local, then the code will create a condor .dag file and a .sub file in order to submit to the cluster. (In Beta)

if int(opts.runlocal) == 1:

    	print('Did you remember to run kinit albert.einstein@LIGO.ORG?')
    	# Need to establish ligo-proxy in order to generate triggers 
    	# and data.cache before running the condor job or local run.
    	system_call = 'ligo-proxy-init -k'
    	os.system(system_call)

	# Set up proxy, paths and some variable names
	detchannelname, detstrip, detGPSstr, imagepathname = setup()

	# Provide some information about settings the user provided 
	# or the default settings
	verbosity()

	# Check to see if set of UniqueIDs has been supplied. If yes then we 
	# we will bypass getting triggers.

	if os.path.isfile(opts.ID)==True:
		# Obtain the IDs and GPStimes
		centraltimelist,IDinput = obtain_IDs()
		print(centraltimelist,IDinput)
	else:
		# Obtain the omicron triggers used to generated the images
		omicrontriggers = get_triggers()

	# Create a cache file indicating what data frames these 
	# images can be found in.
	call_data_find()

	# Now make some images!
	main_call()
	image_pp()
	print("congrats all images were created no problem!")

elif int(opts.runlocal) == 0:

    	print('Did you remember to run kinit albert.einstein@LIGO.ORG?')
    	# Need to establish ligo-proxy in order to generate triggers 
    	# and data.cache before running the condor job or local run.
    	system_call = 'ligo-proxy-init -k'
    	os.system(system_call)

        # Set up proxy, paths and some variable names
        detchannelname, detstrip, detGPSstr, imagepathname = setup()

        # Provide some information about settings the user provided 
        # or the default settings
        verbosity()

        # Obtain the omicron triggers used to generated the images
        omicrontriggers = get_triggers()

        # Create a cache file indicating what data frames these 
        # images can be found in.
        call_data_find()

        # need to save omicron triggers variable to be loaded 
	# by the condor job later
	filename = open("./condor/triggers_{0}".format(detGPSstr) + ".xml",'w')
	omicrontriggers.write(fileobj=filename)

	# Create condor subfile and dagfile
	write_subfile()
	write_dagfile()
	print('Alright all set up please run: condor_submit_dag ./condor/gravityspy.dag')
	sys.exit(1)

else:
	print("running on condor")
	detchannelname, detstrip, detGPSstr, imagepathname = setup()
	print("opening triggers")
	omicrontriggers = SnglBurstTable.read("./condor/triggers_{0}".format(detGPSstr) + ".xml")
	print("opened {0} triggers now generating images".format(len(omicrontriggers)))
	main_call()
	image_pp()
	print("congrats all images were created no problem!")

# House Cleaning

system_call = 'rm -rf {0}'.format(opts.outpath)
os.system(system_call)
